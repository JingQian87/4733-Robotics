# W4733 Robotics HW5

###                                                                 Jing Qian (jq2282)



**Q1. (a)**

$x_k$ is the state vector which describes the location and orientation of the robot at time instant $k$.

$m$ is the set which includes all the time-invariant vector describing the location of landmarks.

$Z_{0:k}$ is the set of all landmark observations.

$U_{0:k}$ is the history of control inputs.

$x_0$ is the robot starting location and orientation.

$P(x_k|x_{k-1}, u_k)$ is the state transition model, which is the probability distribution of $x_k$ conditioned on the previous state $x_{k-1}$ and applied action $u_k$.

$P(z_k|x_k, m)$ is the observation model, which is the probability distribution of $z_k$ conditioned on the state $x_k$ and map $m$.

$P(x_{k-1}, m|Z_{0:k-1}, U_{0:k-1}, x_0)$ is our belief at time instant $k-1$, which is the probability distribution of $x_{k-1}$ and $m$ conditioned on the history set of all landmark ovservations at time $k-1$ : $Z_{0:k-1}$, the history of control inputs at $k-1$: $U_{0:k-1}$ and initial state $x_0$.

$P(x_k, m|Z_{0:k-1}, U_{0:k}, x_0)$ is our belief of $x_k$ and $m$ distribution after we take action at time instant $k$ but haven't observed yet, conditioned on $Z_{0:k-1}, U_{0:k}, x_0$.

$P(x_k, m|Z_{0:k}, U_{0:k}, x_0)$ is our belief of $x_k$ and $m$ distribution after we both take action and make observation at time instant $k$ , conditioned on $Z_{0:k}, U_{0:k}, x_0$.

 So Eq.(4) means that the posterior probability distribution of $(x_k, m)$ conditioned on $(Z_{0:k-1}, U_{0:k}, x_0)$ is equal to the sum of transition probability of $x_k$ conditioned on the previous state $x_{k-1}$ and action $u_k$ times the posterior probability distribution of $(x_{k-1}, m)$ conditioned on $(Z_{0:k-1}, U_{0:k-1}, x_0)$ .

Eq. (5) means that the posterior probability distribution of $(x_k, m)$ conditioned on $(Z_{0:k}, U_{0:k}, x_0)$ is equal to the sum of observation probability of $z_k$ conditioned on state $x_k$ and map $m$ times the posterior probability distribution of $(x_k, m)$ conditioned on $(Z_{0:k-1}, U_{0:k}, x_0)$ , devided by the posterior probability distribution of $z_k$ conditioned on $(Z_{0:k-1}, U_{0:k})$.



**Q1. (b)**

Eq. (4)
$$
P(x_k, m|Z_{0:k-1}, U_{0:k}, x_0) = \int P(x_k, m, x_{k-1}|Z_{0:k-1}, U_{0:k}, x_0)dx_{k-1}
\ \mathrm{(Law\ of\ total\ probability)}\\
= \int P(x_k|m, x_{k-1}, Z_{0:k-1}, U_{0:k}, x_0)\times P(x_{k-1}, m|Z_{0:k-1}, U_{0:k}, x_0)dx_{k-1}\ \mathrm{(Chain\ rule)}\\
= \int P(x_k|x_{k-1},u_k)\times P(x_{k-1}, m|Z_{0:k-1}, U_{0:k}, x_0)dx_{k-1}\ \mathrm{Markov\ assumption}
$$
Eq. (5)
$$
P(x_k, m|Z_{0:k}, U_{0:k}, x_0) = \frac{P(z_k|x_k, m, Z_{0:k-1}, U_{0:k}, x_0)P(x_k, m|Z_{0:k-1}, U_{0:k}, x_0)}{P(z_k|Z_{0:k-1}, U_{0:k}, x_0)}\ \mathrm{Bayes'\ theorem}\\
=\frac{P(z_k|x_k, m)P(x_k, m|Z_{0:k-1}, U_{0:k}, x_0)}{P(z_k|Z_{0:k-1}, U_{0:k})}\ \mathrm{Markov\ assumption}
$$


**Q2. (a)**

Since it is a planar robot on map with $n$ landmarks, we get the dimensionality of following quantities:

$\hat{x}_{k|k}$: 3 x 1.

$\hat{m}_k$: $2n$ x 1.

$z_k$: $2n$ x 1.

$P_{k|k}$: $(2n+3)$ x $(2n+3)$

$Q_k$: 3 x 3

$R_k$ : $2n$ x $2n$

$\nabla f$: 3 x 3

$\nabla h$ : $2n$ x $(2n+3)$

$S_k$: $2n$ x $2n$

$W_k$: $(2n+3)$ x $2n$

So the Eq. (10) should be:
$$
\begin{bmatrix}
\hat{x}_{k|k} \\ \hat{m}_k
\end{bmatrix}
 = \begin{bmatrix}
 \hat{x}_{k|k-1} \\
 \hat{m}_{k-1}
\end{bmatrix}
+W_k[z_k - h(\hat{x}_{k|k-1}, \hat{m}_{k-1})].
$$


**Q2. (b)**
$$
P_{k|k} =\begin{bmatrix}
P_{xx}\ P_{xm}\\
P_{xm}^T\ P_{mm}
\end{bmatrix}_{k|k}
$$

$$
P_{xx, k|k-1} = \nabla f P_{xx, k-1|k-1} \nabla f^T + Q_k
$$

So we have:
$$
P_{k|k-1} = \begin{bmatrix} P_{xx, k|k-1}\qquad P_{xm, k|k-1} \\
P_{xm, k|k-1}^T  \qquad P_{mm, k|k-1}
\end{bmatrix}\\
=
\begin{bmatrix} P_{xx, k|k-1}\qquad \nabla f P_{xm, k-1|k-1} \\
P_{xm, k-1|k-1}^T \nabla f^T \qquad P_{mm, k-1|k-1}
\end{bmatrix}
$$


**Q3. (a)**

Figure 4 in the paper gives the graphical model of SLAM algorithm. We could see that through observations and robot states, the map landmarks are connected and hence dependent. However, if given robot trajectory, which means we block all the robot states, there is no path that could connect these map landmarks. So the landmarks are independent conditioned on the robot trajectory.

Since the landmarks are independent conditioned on the robot trajectory, the map accompanies each particle in sampling is composed of a set of independent Gaussian distributions multiplying continually. At each time step, particles are drawn from distributions and resampling step causes loss of historical particle information. Because of the conditional independence, the historical state information loss in particle resampling is exponential.



**Q3. (b)**

FastSLAM 1.0 use the motion model for its proposal distribution, which is:
$$
x_k^{(i)} \sim P(x_k|x_{k-1}^{(i)}, u_k)
$$
FastSLAM 2.0 includes the current observation for its proposal distribution, which is:
$$
x_k^{(i)} \sim P(x_k|X_{0:k-1}^{(i)}, Z_{0:k}, u_k)
$$
This means that the distribution that particles sampling from in FastSLAM1.0 only conditioned on previous state and action while the distribution that in FastSLAM2.0 also conditioned on the observations, which helps FastSLAM2.0 with the advantage of locally optimal proposal distribution. It means that for each particle, FastSLAM2.0 gives the smallest possible variance in importance weight $w_k^{(i)}$ conditioned upon the available information $X_{0:k-1}^{(i)}, Z_{0:k}, u_k$. 



**Q3. (c)**

No, FastSLAM would not work properly if we never resample. Resample is used for deplete the distory, which helps exploration. If never resample, the FastSLAM will suffer from degeneration and will not work as expected.